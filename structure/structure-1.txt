Lexer:
- Create list of tokens (number, '=', etc.) - No more complexity.

Parser:
- Step through every token in token list.
- Form end result (AST) by repeatedly forming smaller parts.
  - E.g. create an expression by creating terms by creating factors by creating numbers.
- At this point, syntax errors can be caught (i.e. wrong order of operations).

Interpreter:
- Step through AST, beginning at the root and repeatedly resolving its branches.
- A node can either be:
  - An operation, holding more nodes containing arguments.
  - A value, being the final node.
- At this point, semantical errors are caught (i.e. reference of undefined variable).